This experiment compares the different covariance estimation techniques: scalar, diagonal, eigenvalue or quadratic covariance converter.
It was called by:
for cov_est in 1 2 3 4
do
        echo $dim_cov_est
        python Experiment_GP.py -lr 1e-4 -epochs 3 -it 2 -track True -G D4 -A regular_middle -n_eval 10000 -n_val 200 -l 4. -cov $cov_est -file model_compare_cov_est_${cov_est}
done

#for cov_est in 1 2 3 4
#do                                                                                                                                                                                                                                                   echo $dim_cov_est                                                                                                                                                                                                                            python Experiment_GP.py -lr 1e-4 -epochs 30 -it 250 -track True -G D4 -A regular_huge -n_eval 10000 -n_val 200 -l 4. -cov $cov_est                                                                                                   done
#The results are:

1
Running on the GPU

Group: D4
Model type: regular_middle
Number of parameters:  69914
Epoch: 0 | train loss: 2.08430 | train log ll:  -2.08430 | val log ll: -2.03879
Epoch: 1 | train loss: 1.99301 | train log ll:  -1.99301 | val log ll: -1.96991
Epoch: 2 | train loss: 2.04436 | train log ll:  -2.04436 | val log ll: -1.99946
Final log ll: -2.0046534538269043

2
Running on the GPU

Group: D4
Model type: regular_middle
Number of parameters:  70467
Epoch: 0 | train loss: 5.33029 | train log ll:  -5.33029 | val log ll: -2.83473
Epoch: 1 | train loss: 3.68553 | train log ll:  -3.68553 | val log ll: -2.42315
Epoch: 2 | train loss: 2.30914 | train log ll:  -2.30914 | val log ll: -1.87649
Final log ll: -1.972852110862732

3
Running on the GPU

Group: D4
Model type: regular_middle
Number of parameters:  70466
Epoch: 0 | train loss: 2.03465 | train log ll:  -2.03465 | val log ll: -1.80879
Epoch: 1 | train loss: 1.75261 | train log ll:  -1.75261 | val log ll: -1.72590
Epoch: 2 | train loss: 1.71495 | train log ll:  -1.71495 | val log ll: -1.64923
Final log ll: -1.6552940607070923

4
Running on the GPU

Group: D4
Model type: regular_middle
Number of parameters:  71569
Epoch: 0 | train loss: 8.53679 | train log ll:  -8.53679 | val log ll: -4.33961
Epoch: 1 | train loss: 2.17020 | train log ll:  -2.17020 | val log ll: -5.21676
Epoch: 2 | train loss: 5.86173 | train log ll:  -5.86173 | val log ll: -2.50401
Final log ll: -2.969353199005127

1
Running on the GPU

Group: D4
Model type: regular_huge
Number of parameters:  518954
Epoch: 0 | train loss: 14.09988 | train log ll:  -14.09988 | val log ll: -4.41499
Epoch: 1 | train loss: 2.90689 | train log ll:  -2.90689 | val log ll: -2.89211
Epoch: 2 | train loss: 2.92283 | train log ll:  -2.92283 | val log ll: -2.17681
Final log ll: -2.1499552726745605

2
Running on the GPU

Group: D4
Model type: regular_huge
Number of parameters:  521115
Epoch: 0 | train loss: 3.27492 | train log ll:  -3.27492 | val log ll: -2.33383
Epoch: 1 | train loss: 2.24827 | train log ll:  -2.24827 | val log ll: -2.19452
Epoch: 2 | train loss: 2.24015 | train log ll:  -2.24015 | val log ll: -2.54579
Final log ll: -2.3716180324554443

3
Running on the GPU

Group: D4
Model type: regular_huge
Number of parameters:  521114
Epoch: 0 | train loss: 8.14878 | train log ll:  -8.14878 | val log ll: -5.89688
Epoch: 1 | train loss: 4.76872 | train log ll:  -4.76872 | val log ll: -4.68547
Epoch: 2 | train loss: 4.78206 | train log ll:  -4.78206 | val log ll: -4.57835
Final log ll: -4.6618804931640625

4
Running on the GPU

Group: D4
Model type: regular_huge
Number of parameters:  525433
Epoch: 0 | train loss: 5.52314 | train log ll:  -5.52314 | val log ll: -3.68567
Epoch: 1 | train loss: 3.35830 | train log ll:  -3.35830 | val log ll: -3.15409
Epoch: 2 | train loss: 3.94798 | train log ll:  -3.94798 | val log ll: -3.08539
Final log ll: -2.8584482669830322

